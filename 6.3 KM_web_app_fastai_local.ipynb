{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastai.vision.widgets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augments the image to make it easier to extract text\n",
    "def process_img(img):\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) # convert to grayscale\n",
    "    img = imutils.rotate_bound(img, 90) # rotate \n",
    "    img = cv2.resize(img, None, fx=3, fy=3, interpolation=cv2.INTER_CUBIC) # make 3 times larger\n",
    "    img = cv2.GaussianBlur(img,(3,3),0) # add gaussian blur after enlarging\n",
    "    return img\n",
    "    \n",
    "# extracts the text and returns a set of unique words extracted from the text\n",
    "def extract_words(img):\n",
    "    raw_words = pytesseract.image_to_string(img)\n",
    "    # Removes non-alphanumeric characters and underscores and makes lowercase\n",
    "    pattern = re.compile('[\\W_]+')\n",
    "    words = pattern.sub(' ', raw_words).lower()\n",
    "\n",
    "    tokens = set(word_tokenize(words))\n",
    "    #print('extracted words:', words)\n",
    "    return tokens\n",
    "\n",
    "def clean_words(word_data):\n",
    "    # remove words that are 2 chars or lower to reduce noise\n",
    "    word_data_remove_2char = [ x for x in word_data if len(x) > 2]\n",
    "    #word_data_remove_2char_google = [ set(x for x in r if len(x) > 2) for r in word_data_google]\n",
    "\n",
    "    # format list of token sets into a list of strings which are tokens joined by spaces\n",
    "    # [ set('a', 'b'), set ( 'c', 'd', 'e')]  into   ['a b', 'c d e']\n",
    "    word_data_formatted = ' '.join(word_data_remove_2char)\n",
    "    #word_data_google_formatted = [ ' '.join(sets) for sets in word_data_remove_2char_google]\n",
    "    return word_data_formatted\n",
    "\n",
    "def file_to_sentence(a):\n",
    "    # given a file path, apply all transforms and returns a single string\n",
    "    # with all extracted words over 2 characters\n",
    "    a = load_img(a)\n",
    "    a = process_img(a)\n",
    "    a = extract_words(a)\n",
    "    a = clean_words(list(a))\n",
    "    return a    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_sentence(pil_img):\n",
    "    # given a file path, apply all transforms and returns a single string\n",
    "    # with all extracted words over 2 characters\n",
    "    \n",
    "    a = np.array(pil_img)\n",
    "    a = process_img(a)\n",
    "    a = extract_words(a)\n",
    "    a = clean_words(list(a))\n",
    "    return a    \n",
    "\n",
    "def bow_predictor_app_inp(pil_img):\n",
    "    # input either a single file string or a list of file strings to be processed\n",
    "    # returns a prediction (1=KM, 0=0ther), the probability the image is KM, and the max probability ( probability of predicted class -\n",
    "    # so if prediction is 0=other, max prob will tell you the probabilty that the curve is 0)\n",
    "    \n",
    "    # Load linear support vector classifier \n",
    "    with open(\"Y. model - bag of words2.pkl\", 'rb') as file:  \n",
    "        bow_model = pickle.load(file)\n",
    "\n",
    "    # Load count vectorizer\n",
    "    with open('Y. Count vectorizer vocab.pkl', 'rb') as f:\n",
    "        vectorizer_vocab = pickle.load(f)\n",
    "    \n",
    "    # get an error if only one img is passed and use map functionality\n",
    "#     try:\n",
    "#         X_bow = list(map(file_to_sentence, X_input))\n",
    "#     except:\n",
    "#         # if single image, make it look like a list\n",
    "#         X_bow = list(map(file_to_sentence, [X_input]))\n",
    "\n",
    "    X_bow = [img_to_sentence(pil_img)]\n",
    "        \n",
    "    vectorizer = CountVectorizer(vocabulary=vectorizer_vocab)\n",
    "    X_bow = vectorizer.transform(X_bow)\n",
    "    \n",
    "    bow_pred = bow_model.predict(X_bow)\n",
    "    bow_prob = bow_model.predict_proba(X_bow)\n",
    "    bow_max_prob = [max(x) for x in bow_prob]\n",
    "    bow_prob = bow_prob[:,1] # probability the graph is KM\n",
    "    \n",
    "    return bow_pred, bow_prob, bow_max_prob\n",
    "\n",
    "def fastai_predictor_app_inp(pil_img):\n",
    "    # input either a single file string or a list of file strings to be processed\n",
    "    # returns a prediction (1=KM, 0=0ther), the probability the image is KM, and the max probability ( probability of predicted class -\n",
    "    # so if prediction is 0=other, max prob will tell you the probabilty that the curve is 0)\n",
    "    learn_inf = load_learner('model 11 - 25 epoch.pkl')\n",
    "    X_fastai = pil_img\n",
    "\n",
    "    ignored,fastai_pred,prob_tensor = learn_inf.predict(X_fastai)\n",
    "\n",
    "    fastai_pred = 1 - fastai_pred # because in DL model 1=Other. but need to convert so 1=KM\n",
    "    fastai_prob = prob_tensor.numpy()[0] # prob graph is KM\n",
    "    fastai_max_prob = max(prob_tensor).numpy() # returns max values from (0 prob, 1prob) tensor for each input\n",
    "\n",
    "    return fastai_pred, fastai_prob, fastai_max_prob\n",
    "\n",
    "\n",
    "def ensemble_predictor_app_inp(pil_img):\n",
    "    # Function that calculates the ensemble prediction by averaging probablities\n",
    "    # from BOW and fastai model. returns prob and prediction\n",
    "    \n",
    "    # Calculate probabilities from 2 models\n",
    "    fastai_pred, fastai_prob, fastai_max_prob = fastai_predictor_app_inp(pil_img)\n",
    "    bow_pred, bow_prob, bow_max_prob= bow_predictor_app_inp(pil_img)\n",
    "    \n",
    "    a = bow_prob\n",
    "    b= fastai_prob\n",
    "    c= [a,b]\n",
    "    \n",
    "    ensemble_prob = np.mean(c, axis=0)\n",
    "    ensemble_pred = np.round(ensemble_prob)\n",
    "    return ensemble_pred,ensemble_prob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_inf = load_learner('model 11 - 25 epoch.pkl')\n",
    "\n",
    "btn_upload = widgets.FileUpload()\n",
    "out_pl = widgets.Output()\n",
    "lbl_pred = widgets.Label()\n",
    "btn_run = widgets.Button(description='Classify')\n",
    "\n",
    "def on_click_classify(change):\n",
    "    img = PILImage.create(btn_upload.data[-1])\n",
    "    out_pl.clear_output()\n",
    "    with out_pl: display(img.to_thumb(128,128))\n",
    "        \n",
    "    # Choose classification method\n",
    "    \n",
    "    # Bow prediction -------------------------------------------------\n",
    "    #pred, prob, max_prob = bow_predictor_app_inp(img)\n",
    "    \n",
    "    # Fastai prediction ----------------------------------------------\n",
    "    pred, prob, max_prob = fastai_predictor_app_inp(img) # not working\n",
    "    \n",
    "    # Ensemble prediction --------------------------------------------\n",
    "    #pred, prob = ensemble_predictor_app_inp(img) \n",
    "    \n",
    "    lbl_pred.value = f'Prediction: {pred}, Prob: {prob}'\n",
    "\n",
    "btn_run.on_click(on_click_classify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaplan Meir Classifier\n",
    "Use the buttons below to upload an image, then click to classify the image. \n",
    "1 = Kaplan Meier\n",
    "0 = Not Kaplan Meier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c64101fcf6a4f9cb10711ef6dc1c608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Please upload an image'), FileUpload(value={}, description='Upload'), Button(descrâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "VBox([widgets.Label('Please upload an image'), \n",
    "      btn_upload, btn_run, out_pl, lbl_pred])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
